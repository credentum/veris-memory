version: "3.8"

services:
  # Context Store MCP Server - Hetzner optimized
  context-store:
    build:
      context: .
      dockerfile: Dockerfile.hetzner
    ports:
      - "127.0.0.1:8000:8000" # Only bind to localhost for Tailscale access
    environment:
      - QDRANT_URL=http://qdrant:6333
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - REDIS_URL=redis://redis:6379
      - MCP_SERVER_PORT=8000
      - LOG_LEVEL=info
      # Hetzner-specific configuration
      - HARDWARE_PROFILE=hetzner-dedicated
      - MEMORY_PROFILE=64gb
      - CPU_PROFILE=6core-ryzen5600x
      - STORAGE_PROFILE=raid1-nvme
      # Tailscale configuration
      - TAILSCALE_AUTHKEY=${TAILSCALE_AUTHKEY}
      - TAILSCALE_HOSTNAME=${TAILSCALE_HOSTNAME:-veris-memory-hetzner}
    volumes:
      # RAID1 storage integration
      - /raid1/docker-data/context-store:/app/data
      - /raid1/docker-data/logs:/app/data/logs
    depends_on:
      qdrant:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - context-store-network
    # Resource limits optimized for 64GB/6-core system
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: "2.0"
        reservations:
          memory: 8G
          cpus: "1.0"

  # Vector Database (Qdrant) - High-performance configuration
  qdrant:
    image: qdrant/qdrant:v1.12.1@sha256:d774e7bb65744454984c6021637a0da89271f30df15e48601a9fafc926d26b1f
    ports:
      - "127.0.0.1:6333:6333" # HTTP API (Tailscale only)
      - "127.0.0.1:6334:6334" # gRPC port (Tailscale only)
    volumes:
      # RAID1 NVMe storage
      - /raid1/docker-data/qdrant:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__SERVICE__ENABLE_CORS=true
      # High-performance settings for 64GB system
      - QDRANT__SERVICE__MAX_REQUEST_SIZE_MB=256
      - QDRANT__STORAGE__PERFORMANCE__MAX_SEARCH_THREADS=8
      - QDRANT__STORAGE__OPTIMIZERS__DEFAULT_SEGMENT_NUMBER=8
      - QDRANT__STORAGE__WAL__WAL_CAPACITY_MB=1024
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    networks:
      - context-store-network
    # Resource allocation for high-performance vector operations
    deploy:
      resources:
        limits:
          memory: 20G
          cpus: "4.0"
        reservations:
          memory: 10G
          cpus: "2.0"

  # Graph Database (Neo4j) - High-memory configuration
  neo4j:
    image: neo4j:5.15-community@sha256:69c579facb7acab1e98f28952b91144c89e469a081804a5dafebd6c3030433b8
    ports:
      - "127.0.0.1:7474:7474" # HTTP (Tailscale only)
      - "127.0.0.1:7687:7687" # Bolt (Tailscale only)
    volumes:
      # RAID1 NVMe storage for data and logs
      - /raid1/docker-data/neo4j/data:/data
      - /raid1/docker-data/neo4j/logs:/logs
      - /raid1/docker-data/neo4j/import:/var/lib/neo4j/import
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD}
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_default__listen__address=0.0.0.0
      - NEO4J_dbms_default__advertised__address=localhost
      - NEO4J_dbms_connector_https_advertised__address=localhost:7473
      - NEO4J_dbms_connector_http_advertised__address=localhost:7474
      - NEO4J_dbms_connector_bolt_advertised__address=localhost:7687
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      # High-memory configuration for 64GB system
      - NEO4J_server_memory_heap_initial__size=20G
      - NEO4J_server_memory_heap_max__size=20G
      - NEO4J_server_memory_pagecache_size=16G
      - NEO4J_server_jvm_additional=-XX:+UseG1GC
      - NEO4J_server_jvm_additional=-XX:+UnlockExperimentalVMOptions
      - NEO4J_server_jvm_additional=-XX:+UseTransparentHugePages
      # Performance tuning for NVMe storage
      - NEO4J_server_db_query_cache_size=32768
      - NEO4J_server_db_query_timeout=120s
    healthcheck:
      test:
        [
          "CMD",
          "sh",
          "-c",
          "cypher-shell -u neo4j -p $$NEO4J_PASSWORD 'RETURN 1'",
        ]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 120s
    restart: unless-stopped
    networks:
      - context-store-network
    # Resource allocation for graph operations
    deploy:
      resources:
        limits:
          memory: 24G
          cpus: "3.0"
        reservations:
          memory: 20G
          cpus: "2.0"

  # Cache/KV Store (Redis) - High-memory configuration
  redis:
    image: redis:7.2.5-alpine@sha256:3d2c7e0e2cb6af5e43f3e21ec0fd3e0b4b4d5af5e4f0c9b4e8b0f8b0f8b0f8b0
    ports:
      - "127.0.0.1:6379:6379" # Tailscale only
    volumes:
      # RAID1 NVMe storage for persistence
      - /raid1/docker-data/redis:/data
    command: >
      redis-server
      --appendonly yes
      --maxmemory 8gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --tcp-keepalive 300
      --timeout 0
      --tcp-backlog 511
      --databases 16
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - context-store-network
    # Resource allocation for caching
    deploy:
      resources:
        limits:
          memory: 10G
          cpus: "1.0"
        reservations:
          memory: 8G
          cpus: "0.5"

  # Hardware monitoring service
  hardware-monitor:
    build:
      context: .
      dockerfile: Dockerfile.hetzner
    command: ["/app/monitoring/hardware-monitor.sh"]
    volumes:
      - /raid1/docker-data/monitoring:/app/monitoring/data
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /dev:/host/dev:ro
    environment:
      - HOST_PROC=/host/proc
      - HOST_SYS=/host/sys
      - HOST_DEV=/host/dev
    restart: unless-stopped
    networks:
      - context-store-network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"

  # Backup service for RAID1 redundancy
  backup-service:
    build:
      context: .
      dockerfile: Dockerfile.hetzner
    command: ["/app/backup/raid1-backup.sh"]
    volumes:
      - /raid1/docker-data:/raid1/docker-data:ro
      - /raid1/backups:/raid1/backups
    environment:
      - BACKUP_SCHEDULE="0 2 * * *" # Daily at 2 AM
      - BACKUP_RETENTION_DAYS=7
    restart: unless-stopped
    networks:
      - context-store-network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "0.5"

volumes:
  # All volumes use RAID1 NVMe storage for high performance and redundancy
  qdrant_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /raid1/docker-data/qdrant
  neo4j_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /raid1/docker-data/neo4j/data
  neo4j_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /raid1/docker-data/neo4j/logs
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /raid1/docker-data/redis

networks:
  context-store-network:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: br-context-store
