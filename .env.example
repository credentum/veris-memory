# Context Store Environment Configuration
# Copy this file to .env and update with your values

# Database Connections (public configuration)
QDRANT_URL=http://localhost:6333
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
REDIS_URL=redis://localhost:6379

# Server Configuration
MCP_SERVER_PORT=8000
LOG_LEVEL=info

# Sprint 13: API Key Authentication
# Enable/disable API key authentication
AUTH_REQUIRED=true

# Environment mode (development allows default test key)
ENVIRONMENT=development

# API Key for MCP Server
# Format: vmk_{prefix}_{random}:user_id:role:is_agent
# Roles: admin, writer, reader, guest
# is_agent: true (AI agent) or false (human user)
# Example: API_KEY_MCP=vmk_mcp_d9ef8d8699ca748e5a484c5026ecdc2a:mcp_server:writer:true

# SECURITY NOTE:
# Do NOT put sensitive passwords or API keys here!
# Use GitHub Secrets for deployment, or .env.local (gitignored) for local development
#
# For GitHub Actions deployment (deploy-dev.yml):
# 1. Go to GitHub repository Settings → Secrets and variables → Actions
# 2. Add secret: API_KEY_MCP=vmk_mcp_xxx:mcp_server:writer:true
# 3. Generate random string: openssl rand -hex 16
# 4. Format: vmk_mcp_{random}:mcp_server:writer:true
# 5. deploy-dev.yml automatically writes secret to .env on the server
#
# For local development:
# 1. Create .env.local (gitignored)
# 2. Add: NEO4J_PASSWORD=your_password_here
# 3. Add: API_KEY_MCP=vmk_mcp_xxx:mcp_server:writer:true

# PR #170: Cache and Embedding Configuration
# Cache TTL in seconds (default: 300 = 5 minutes)
# Increase for stable data (900=15min, 3600=1hr), decrease for real-time data (60-180s)
VERIS_CACHE_TTL_SECONDS=300

# Embedding failure behavior (default: false = graceful degradation)
# true = fail fast (return error if embeddings unavailable)
# false = graceful degradation (store context without vector if embeddings fail)
STRICT_EMBEDDINGS=false

# Embedding vector dimensions (default: 768 for all-mpnet-base-v2)
# Common values: 384 (all-MiniLM-L6-v2), 768 (all-mpnet-base-v2), 1024 (large models)
EMBEDDING_DIM=768

# =============================================================================
# TeamAI Voice Platform Configuration
# =============================================================================

# LiveKit Voice Server Configuration
# Get credentials from LiveKit Cloud (https://cloud.livekit.io)
# or self-host LiveKit server
LIVEKIT_API_KEY=APIxxxxxxxxxxxxx
LIVEKIT_API_SECRET=secretxxxxxxxxxxxxx
LIVEKIT_API_WEBSOCKET=wss://your-instance.livekit.cloud
LIVEKIT_WEBHOOK_URLS=

# Voice Bot - API Key for MCP Server Access (Sprint 13)
# Format: vmk_voicebot_{random}:voice_bot:writer:true
# Example: API_KEY_VOICEBOT=vmk_voicebot_a1b2c3d4:voice_bot:writer:true
# Generate with: openssl rand -hex 16
API_KEY_VOICEBOT=vmk_voicebot_CHANGE_ME:voice_bot:writer:true

# Voice Bot - Author Attribution (Sprint 13)
# Prefix for author field in stored contexts (author will be: {prefix}_{user_id})
# Default: voice_bot (results in authors like: voice_bot_alice, voice_bot_bob)
VOICE_BOT_AUTHOR_PREFIX=voice_bot

# Voice Bot - Retry Logic (Sprint 13)
# Enable retry with exponential backoff for improved reliability
# PR #3 showed retry reduces error rate from 98% to <5%
ENABLE_MCP_RETRY=true
MCP_RETRY_ATTEMPTS=3

# Speech-to-Text Provider Configuration
# Options: whisper (OpenAI), deepgram, google
# OpenAI models: whisper-1, gpt-4o-mini-transcribe, gpt-4o-transcribe
STT_PROVIDER=whisper
STT_API_KEY=

# Text-to-Speech Provider Configuration
# Options: openai, elevenlabs, google, azure
# OpenAI models: tts-1, gpt-4o-mini-tts
TTS_PROVIDER=openai
TTS_API_KEY=

# OpenAI API Key (for Whisper STT and TTS)
# Same key used for both STT and TTS
OPENAI_API_KEY=sk-your_openai_api_key_here

# Voice Bot Feature Flags
ENABLE_VOICE_COMMANDS=true
ENABLE_FACT_STORAGE=true
ENABLE_CONVERSATION_TRACE=true

# Voice Bot CORS Configuration
# Comma-separated list of allowed origins for production
# Development: CORS_ORIGINS=*
# Production: CORS_ORIGINS=https://app.example.com,https://admin.example.com
CORS_ORIGINS=*

# Voice Bot Service Configuration
# LOG_LEVEL is inherited from main configuration above
